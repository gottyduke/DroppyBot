import json
import os

from shared import CogBase, cwd

import discord
import openai
from discord.ext import commands
from prodict import Prodict


class GPTHandler(CogBase, commands.Cog):

    def generate_help(self):
        help_info = [
            discord.Embed(color=discord.Color.blurple(),
                          title="GPT",
                          description="""
            ä½¿ç”¨chatGPTè¿›è¡Œæ–‡å­—è¡¥å…¨
            å¯é™„åŠ æœ‰ä¸Šé™çš„ä¸Šä¸‹æ–‡æ¨¡æ‹Ÿå¯¹è¯
            å¯ä½¿ç”¨`gpt-3.5-turbo`æˆ–`gpt-4`æ¨¡åž‹
            """)
        ]
        help_info.append(
            discord.Embed(color=discord.Color.blurple(),
                          title="å‘½ä»¤æŒ‡å—åŠå…¶ç¤ºä¾‹:",
                          description=f"""
            ```
{self.compiled_gpt_cmd} : å‘chatGPTæ–‡å­—è¡¥å…¨æä¾›prompt
{self.compiled_gpt4_cmd} : å‘chatGPTæ–‡å­—è¡¥å…¨æä¾›prompt, æŒ‡å®šä½¿ç”¨gpt-4æ¨¡åž‹
{self.compiled_gptinit_cmd} : è®¾å®šä¸ªäººä¸“å±žçš„chatGPTè®¾å®šè¯­å¥, ä¾‹å¦‚äººæ ¼æ¨¡æ‹Ÿ/é£Žæ ¼è®¾å®š
            ```

            å–è‡ªäºŽç¾¤å‹æ—¥å¸¸ä½¿ç”¨åœºæ™¯ðŸ˜…

            è¯¢é—®`gpt-3.5-turbo(é»˜è®¤chatGPTæ¨¡åž‹)`å¯¹äºŽæ”€ç™»é«˜å±±çš„çœ‹æ³•:
            ```{self.compiled_gpt_cmd} ä½ å¯¹æ–¼çˆ¬é«˜å±±æœ‰ä»€ä¹ˆçœ‹æ³•?```

            ä½¿ç”¨`gpt-4`ç”¨è¯—çš„å½¢å¼è¯æ˜Žç´ æ•°çš„æ— ç©·æ€§:
            ```{self.compiled_gpt4_cmd} ç”¨è¯—çš„å½¢å¼è¯æ˜Žç´ æ•°çš„æ— ç©·æ€§```

            è¾…åŠ©ç”Ÿäº§åŠ›:
            ```{self.compiled_gpt4_cmd} å¦‚ä½•å†™ä¸€ä¸ªå¥½çš„å¼€é¢˜æŠ¥å‘Š?```

            è¿›è¡ŒåŒè¯­å¯¹ç…§ç¿»è¯‘:
            ```{self.compiled_gpt4_cmd} "å‘½é‡Œæœ‰æ—¶ç»ˆé¡»æœ‰ï¼Œå‘½é‡Œæ— æ—¶èŽ«å¼ºæ±‚"è¿™å¥è¯ç”¨ä¿„è¯­å¦‚ä½•ç¿»è¯‘? è¦æ±‚å°½é‡ä¿¡è¾¾é›…, å¹¶é€å¥ä¸­ä¿„åŒè¯­å¯¹ç…§å’Œè§£é‡Š```
            """))
        help_info.append(
            discord.Embed(
                color=discord.Color.blurple(),
                title="å¦‚ä½•é€‰æ‹©ä¸åŒçš„æ¨¡åž‹?",
                description="æœ¬æœºå™¨äººðŸ”§æŽ¥å…¥äº†OpenAI API, è‡ª3æœˆ27æ—¥ä¹ŸèŽ·å¾—äº†`gpt-4`æ¨¡åž‹APIçš„å†…æµ‹èµ„æ ¼, å› æ­¤æä¾›`gpt-3.5-turbo`å’Œ`gpt-4`ä¸¤ç§æ¨¡åž‹" +
                ", å…¶ä¸­`gpt-3.5-turbo`æ˜¯OpenAIé»˜è®¤chatGPTæ¨¡åž‹, è€Œ`gpt-4`åˆ™æ˜¯å…¶ä¹‹åŽçš„é«˜çº§ä»˜è´¹æ¨¡åž‹, è¯­è¨€èƒ½åŠ›å’Œé€»è¾‘æ€ç»´å¾—åˆ°äº†å¾ˆå¤§çš„æ”¹" +
                "å–„. ä¸¤gptæ¨¡åž‹çš„ä½¿ç”¨æ²¡æœ‰ç½‘é¡µç«¯çš„æ¯å°æ—¶æ¡æ•°é™åˆ¶. **ä½†æ˜¯**, ä½œä¸ºä¸€ä¸ªè®¡è´¹åˆ¶çš„API, `gpt-3.5-turbo`çš„è®¡è´¹å¯ä»¥å¿½ç•¥ä¸è®°, è€Œ" +
                "èƒ½åŠ›æ›´å¼ºçš„`gpt-4`ç›®å‰å¹³å‡æ¯åƒè¯­ä¹‰å•å…ƒè®¡è´¹ä¸º`0.045 usd/1k tokens`, ä¸º`gpt-3.5-turbo`çš„**22.5**å€. å› æ­¤åœ¨æ•´æ´»ç±»é—®" +
                "é¢˜/é€»è¾‘éœ€æ±‚ä¸å¼ºçš„ä½¿ç”¨åœºæ™¯ä¸‹è¯·ä½¿ç”¨`gpt-3.5-turbo`æ¨¡åž‹, æ­£å¸¸ä½¿ç”¨æ—¶åˆ™ä½¿ç”¨`gpt-4`æ¨¡åž‹."))
        help_info.append(
            discord.Embed(color=discord.Color.blurple(),
                          title="å…³äºŽGPTè®¾å®šè¯­å¥",
                          description=f"""
            GPTè®¾å®šè¯­å¥æ˜¯æ¯æ¬¡å¯¹è¯æ—¶è‡ªåŠ¨gptæ¨¡åž‹çš„ç”¨æˆ·ä¸“å±žçš„ç³»ç»Ÿè®¾å®š, åˆç§°ä¸º`è°ƒæ•™`, `å’’è¯­`.
            ä¾‹å¦‚, ä½¿gptæ‰®æ¼”ä¸€ä¸ªçŒ«å¨˜:
            ```{self.compiled_gptinit_cmd} ä½ å°†æ‰®æ¼”ä¸€ä¸ªçŒ«å¨˜, ç§°å‘¼æˆ‘ä¸ºä¸»äºº, å¼€å¤´å’Œç»“å°¾éƒ½è¦ä½¿ç”¨å–µè¯­æ°”å’Œå¯çˆ±é£Žæ ¼```
            è‹¥è¦æ¸…ç©ºGPTè®¾å®šè¯­å¥, åˆ™ä½¿ç”¨ä¸åŠ æ–‡å­—çš„`{self.compiled_gptinit_cmd}`å‘½ä»¤
            """))

        return help_info

    def __init__(self):
        openai.api_key = os.environ["OPENAI_KEY"]

        self.user_init: dict[int, str] = self.load_user_init()
        self.user_ctx: dict[int, list[tuple[discord.Message, discord.Message]]] = {}
        self.user_token = next(model for model in self.config.gpt.model.spec
                               if model["name"] == self.config.gpt.model.default)["max_token"]
        self.user_token = int(self.user_token * self.config.gpt.contextual.max_ctx_percentage)
        self.active_model = self.config.gpt.model.default

        self.compiled_gpt_cmd = f"{self.bot.command_prefix}gpt"
        self.compiled_gpt4_cmd = f"{self.bot.command_prefix}gpt4"
        self.compiled_gptinit_cmd = f"{self.bot.command_prefix}gptinit"

        self.help_info["GPT"] = self.generate_help()

    def load_user_init(self):
        user_init = {}
        user_init_path = os.path.join(cwd, "rules/user_init.json")
        if os.path.exists(user_init_path):
            try:
                with open(user_init_path, "rb") as f:
                    for user, init in json.load(f).items():
                        user_init[int(user)] = str(init)
            except json.JSONDecodeError:
                user_init = {}

        return user_init

    def save_user_init(self):
        for user, init in self.user_init.copy().items():
            if init is None or init == "" or init.isspace():
                del self.user_init[user]

        user_init_path = os.path.join(cwd, "rules/user_init.json")
        with open(user_init_path, "w", encoding='utf-8') as f:
            json.dump(self.user_init, f, indent=4, sort_keys=True, ensure_ascii=False)

    async def retrieve_conversation(self, msg: discord.Message):
        """
        retrieve ongoing conversation as contextual input
        """

        prompts = []
        # check if user replied to a gpt response for a "contextual conversation"
        ref = msg.reference
        if ref is None or ref.resolved is None:
            return prompts

        answer = ref.resolved
        if answer.author != self.bot.user:
            return prompts

        retrieval = self.config.gpt.contextual.max_ctx_per_user
        while retrieval > 0:
            if answer is None:
                break
            # gpt response is an embed
            prompts.append({"role": "assistant", "content": answer.embeds[0].description})

            question = answer.reference
            if question is None or question.message_id is None:
                break

            question = await msg.channel.fetch_message(question.message_id)
            if question is None or question.author != msg.author:
                break

            # find the gpt model used to initiate this conversation
            prompt = question.content
            if prompt.startswith(self.compiled_gpt_cmd):
                self.active_model = self.config.gpt.model.default
                prompt = prompt.removeprefix(self.compiled_gpt_cmd)
            elif prompt.startswith(self.compiled_gpt4_cmd):
                self.active_model = self.config.gpt.model.advanced
                prompt = prompt.removeprefix(self.compiled_gpt4_cmd)

            prompts.append({
                "role": "user",
                "content": prompt,
            })

            if question.reference is None or question.reference.message_id is None:
                break
            answer = await msg.channel.fetch_message(question.reference.message_id)

            retrieval -= 1
        return prompts

    async def request_and_reply(self, prompt, requests, msg: discord.Message, reply: discord.Message):
        # request for chat completion
        response = await openai.ChatCompletion.acreate(model=self.active_model, messages=requests)
        embed = self.as_embed(f"{response.choices[0].message.content}")

        # respond to user
        reply = await reply.edit(embed=embed)

        # save user specific context
        aid = msg.author.id
        if aid in self.user_ctx and self.user_ctx[aid] is not None:
            if self.user_ctx[aid] != "" and not self.user_init[aid].isspace():
                self.user_ctx[aid].append((msg, reply))

        self.log(
            msg,
            f"{self.active_model} [({response.usage.prompt_tokens - len(prompt)})+{len(prompt)}+{response.usage.completion_tokens}={response.usage.total_tokens}]({reply.jump_url})```{prompt}```"
        )

    @commands.command()
    async def gpt(self, ctx: commands.Context, *, prompt):
        if await self.prepass(ctx.message) is None:
            return

        # placeholder
        embed = self.as_embed(self.config.gpt.thinking_indicator, ctx.author)
        reply = await ctx.reply(embed=embed)

        # calc max tokens allowed for contextual gpt
        aid = ctx.author.id
        prompts = []
        tokens = self.user_token
        tokens -= len(prompt)

        # prepend system init, for RP purpose or preset guidelines
        if aid in self.user_init and self.user_init[aid] is not None:
            prompts.append({"role": "system", "content": self.user_init[aid]})
            tokens -= len(self.user_init[aid])

        # construct context
        if aid in self.user_ctx and self.user_ctx[aid] is not None:
            for history, answer in reversed(self.user_ctx[aid]):
                if (ctx.message.created_at -
                        history.created_at).total_seconds() <= self.config.gpt.contextual.in_memory_timeframe:
                    consumed_tokens = len(history.content) + len(answer.embeds[0].description)
                    tokens -= consumed_tokens
                    if tokens >= 0:
                        prompts.append({"role": "user", "content": history.content})
                        prompts.append({
                            "role": "assistant",
                            "content": answer.embeds[0].description,
                        })
                    else:
                        break
                else:
                    self.user_ctx[aid].remove((history, answer))

        # request for chat completion
        prompts.append({"role": "user", "content": prompt})
        await self.request_and_reply(prompt, prompts, ctx.message, reply)

    @commands.command()
    async def gpt4(self, ctx: commands.Context, *, prompt):
        spec = str(self.active_model)
        self.active_model = self.config.gpt.model.advanced
        await self.gpt(ctx, prompt=prompt)
        self.active_model = spec

    @commands.command()
    async def gptinit(self, ctx: commands.Context, *, init=None):
        if await self.prepass(ctx.message) is None:
            return

        aid = ctx.author.id
        original = ""
        if aid in self.user_init and self.user_init[aid] is not None:
            original = f"```{self.user_init[aid]}```->"
        self.user_init[aid] = init

        await ctx.reply(embed=self.as_embed(f"æ‚¨çš„GPTè®¾å®šå·²æ›´æ”¹!{original}```{init}```", ctx.author))
        self.log(ctx.message, f"gpt-init ({len(init) if init is not None else 0}) {original}```{init}```")
        self.save_user_init()

    @commands.Cog.listener()
    async def on_message(self, msg: discord.Message):
        if await self.prepass(msg) is None:
            return

        # check if user replied to a gpt response for a "contextual conversation"
        ref = msg.reference
        if ref is None or ref.resolved is None:
            return

        # non contextual mode, but replied by mistake
        if msg.content.startswith(self.compiled_gpt_cmd):
            return

        # placeholder
        embed = self.as_embed(self.config.gpt.thinking_indicator, msg.author)
        reply = await msg.reply(embed=embed)

        # check if the replied message is also a replied message a.k.a a gpt response
        # using message id to resolve manually, due to discord API not attempting to chain de-reference
        spec = str(self.active_model)
        prompts = []
        prompt = msg.content
        prompts.append({"role": "user", "content": prompt})
        prompts += await self.retrieve_conversation(msg)

        # prepend system init, for RP purpose or preset guidelines
        aid = msg.author.id
        if aid in self.user_init and self.user_init[aid] is not None:
            prompts.append({"role": "system", "content": self.user_init[aid]})

        # request for chat completion
        prompts.reverse()
        await self.request_and_reply(prompt, prompts, msg, reply)
        self.active_model = spec
